tags:: 消息队列，io，kafka

- 批量消息提升服务端处理能力
	- 虽然produer只提供了单条发送的send方法，但是发送的时候，采用了异步批量发送的机制。
	- 会先把这条消息，存放在内存中缓存起来，然后选择合适的 时机把缓存中的所有消息组成一批，一次性发给 Broker。简单地说，就是攒一波一起发。
	- 在broker里，也不会还原成一条一条处理，写入磁盘，读磁盘，复制到其他副本，都是按照一条 批消息 来处理的
	- 消费的时候，也是按批为单位传递。拉到消息后，在客户端把批消息解开，一条一条交给用户代码处理
- 顺序读写提升磁盘IO性能
	- 在 SSD（固态 硬盘）上，顺序读写的性能要比随机读写快几倍，如果是机械硬盘，这个差距会达到几十 倍。
	- 因为去读写数据的时候，要先寻址，找到数据在磁盘上的物理位置。
	- 对于每个分区，把从 Producer 收到的消息，顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的 文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件 中的某个位置开始，顺序地把消息读出来。
- 利用pageCache加速消息读写
	- PageCache 就是操作系统在内存中给磁盘上的文件建立的缓 存。
	- 应用程序在写入文件的时候，操作系统会先把数据写入到内存中的 PageCache，然后再一 批一批地写到磁盘上。读取文件的时候，也是从 PageCache 中来读取数据，这时候会出现 两种可能情况。
		- 一种是 PageCache 中有数据，那就直接读取，这样就节省了从磁盘上读取数据的时间；
		- 另 一种情况是，PageCache 中没有数据，这时候操作系统会引发一个缺页中断，应用程序的 读取线程会被阻塞，操作系统把数据从文件中复制到 PageCache 中，然后应用程序再从 PageCache 中继续把数据读出来，这时会真正读一次磁盘上的文件，这个读的过程就会比 较慢。
	- 使用完某块pagecache后，不会立马清除，尽可能保存，一般清除策略：LRU
	- 一般来说，消息刚刚写入 到服务端就会被消费，按照 LRU 的“优先清除最近最少使用的页”这种策略，读取的时 候，对于这种刚刚写入的 PageCache，命中的几率会非常高。（？？？？为啥呢？有积压的话，还是要先进先出吧
	- 大部分情况下，消费读消息都会命中 PageCache，带来的好处有两个：一个是 读取的速度会非常快，另外一个是，给写入消息让出磁盘的 IO 资源，间接也提升了写入的 性能。
- 零拷贝
	- 服务端处理消费逻辑：
		- 首先，从文件中找到消息数据，读到内存中；
		- 然后，把消息通过网络发给客户端。
		- 做的操作是
			- 1. 从文件复制数据到 PageCache 中，如果命中 PageCache，这一步可以省掉；
			- 2. 从 PageCache 复制到应用程序的内存空间中，也就是我们可以操作的对象所在的内 存；
			- 3. 从应用程序的内存空间复制到 Socket 的缓冲区，这个过程就是我们调用网络应用框架 的 API 发送数据的过程。
	- 零拷贝
		- 直接从 PageCache 中把数据复制到 Socket 缓冲区中，这样不仅减少一次数据复 制
		- 更重要的是，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复 制，不需要 CPU 参与，速度更快。